<!DOCTYPE html>
<html>
    <script src="https://maps.googleapis.com/maps/api/js"></script>
    <script type="text/javascript" src="https://www.google.com/jsapi"></script>
    <script src="http://code.jquery.com/jquery-1.11.1.min.js"></script>

    <link rel="stylesheet" href="//khan.github.io/KaTeX/bower_components/katex/dist/katex.min.css" type="text/css" rel="stylesheet">
    <script src="//khan.github.io/KaTeX/bower_components/katex/dist/katex.min.js" type="text/javascript"></script>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Paper Review - Universal Intelligence - A Definition of Machine Intelligence &#8211; DGY Life Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="A proud WE-ARE-NOT-DOOMED fan.">
    <meta name="author" content="Yuhuang Hu">
    <meta name="keywords" content="oldtimes">
    <link rel="canonical" href="http://dgyblog.com/oldtimes/2012/03/10/paper-review-universal-intelligence/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for DGY Life Blog" href="/feed.xml" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?201511031732" type="text/css">

    <!-- Fonts -->
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
      <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
    

    <link rel="stylesheet" type="text/css"
	  href="http://spratt.github.io/Computer-Modern/cmserif.css" />
    
    <!-- Verifications -->
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Paper Review - Universal Intelligence - A Definition of Machine Intelligence">
    <meta property="og:description" content="A proud WE-ARE-NOT-DOOMED fan.">
    <meta property="og:url" content="http://dgyblog.com/oldtimes/2012/03/10/paper-review-universal-intelligence/">
    <meta property="og:site_name" content="DGY Life Blog">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
        <meta name="twitter:site" content="@duguyue100" />
    
    <meta name="twitter:title" content="Paper Review - Universal Intelligence - A Definition of Machine Intelligence" />
    <meta name="twitter:description" content="A proud WE-ARE-NOT-DOOMED fan." />
    <meta name="twitter:url" content="http://dgyblog.com/oldtimes/2012/03/10/paper-review-universal-intelligence/" />
    
    
</head>

<body class="site">
  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="http://dgyblog.com" class="site-title">DGY Life Blog</a>
      <nav class="site-nav">
        <a href="/about/">About</a>

      </nav>
      <div class="clearfix"></div>
      
        <div class="social-icons">
  <div class="social-icons-right">
    
      <a class="fa fa-github" href="https://github.com/duguyue100"></a>
    
    
    
    <a class="fa fa-rss" href="/feed.xml"></a>
    
      <a class="fa fa-twitter" href="https://twitter.com/duguyue100"></a>
    
    
      <a class="fa fa-google-plus" href="https://plus.google.com/+YuhuangHu/posts"></a>
    
    
      <a class="fa fa-envelope" href="mailto:duguyue100@gmail.com"></a>
    
    
    
    
  </div>
  <div class="right">
    
    
    
  </div>
</div>
<div class="clearfix"></div>

      
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        


<div class="post-header mb2">
  <h2>Paper Review - Universal Intelligence - A Definition of Machine Intelligence</h2>
  <span class="post-meta">Mar 10, 2012</span><br>
  
  <span class="post-meta small">
  
    5 minute read
  
  </span>
</div>

<article class="post-content">
  <p>Four days ago, a friend passed me a paper called <em>Universal Intelligence: A Definition of Machine Intelligence</em>. At first, I thought this paper just proposes a wired mathematical model based on some philosophical method, because the whole section 2 is describing and explaining the so-called <strong>Natural Intelligence</strong>. Basically, finally I skip section 2 and start my reading from section 3. And section 3 presents a very great mathematical model. Although this model is still built on common definition, however, this model still determines a possible way to compute and measure the level of intelligence of a certain agent.</p>

<p>You can download this paper from <a href="http://arxiv.org/abs/0712.3329">here</a>. The author are <strong>Shane Legg</strong> from Switzerland and <strong>Marcus Hutter</strong> from Australia.</p>

<p>This post is more focusing on the mathematical deduction. If you want to find more analysis on interpretation, please go download the original paper. Now, universal intelligence is a important topic on <strong>AGI</strong> which refers to Artificial General Intelligence. The reason why I am interested in this topic is that I finally find a mathematical model to measure the learning or intelligence model I design. This sentence may be blurring as a low quality picture. In the near future, I would summarize the work I currently doing and show the relationship between my research and AGI.</p>

<p>As we know, when a human interacts with a certain environment, the human’s action would get sort of feedback from environment. Usually, this feedback is simply defined as percepts. In this case, the percepts is divided into two parts: observation and reward. Since we are not just simply observe the environment all the time, via interaction, we also gain something, which is called reward from environment. For example, in a Gambling game, human get money when they won. And the money in this case is a type of reward gained from the game. Even the guy lose the money, that means his action is failed. And the model still can give a value to measure this situation. Therefore, based on our discussion, the essential elements in a intelligence system are environment, agent, actions, reward and observation.</p>

<table>
  <tbody>
    <tr>
      <td>Let <script type="math/tex">\mathcal{A}=\{a_{1},a_{2},\ldots,a_{n}\}</script> as a finite action space, <script type="math/tex">\mathcal{O}=\{o_{1},o_{2},\ldots,o_{n}\}</script> as a finite observation space, <script type="math/tex">\mathcal{R}=\{r_{1},r_{2},\ldots,r_{n}\}</script> as a finite reward space which is always a subset of the rational unit interval <script type="math/tex">[0,1]\cap\mathbb{Q}</script>. Furthermore, a finite set which is called perception space <script type="math/tex">\mathcal{P}=\mathcal{O}\times\mathcal{R}</script> is defined. As we discuss previously, the agent received perception from environment and perform a certain action. The action would also affect the perception provided by environment. Thus, the history of this agent can be denoted by <script type="math/tex">o_{1}r_{1}a_{1}o_{2}r_{2}a_{2}o_{3}r_{3}a_{3}o_{4}\ldots</script>. Normally, we denote agent as a function <script type="math/tex">\pi</script>. In this case, even though we do not have a direct way to determine the next action which will perform by agent, we can using the history to express it, for example, for <script type="math/tex">a_{3}</script>, the action is determined by $$\pi(a_{3}</td>
      <td>o_{1}r_{1}a_{1}o_{2}r_{2})<script type="math/tex">. The expression represent the probability of action</script>a_{3}<script type="math/tex">in the third cycle based on the current history. This expression do not require that the environment is deterministic or full-observable. Similarly, we can define a environment</script>\mu<script type="math/tex">based on current history. In this case, the role of environment is reversed.</script>\pi<script type="math/tex">take action as input, therefore, environment could take observation and reward ad input. Thus, for</script>o_{3}r_{3}<script type="math/tex">, the expression could be</script>\mu=(o_{3}r_{3}</td>
      <td>o_{1}r_{1}a_{1}o_{2}r_{2}a_{2})<script type="math/tex">. Based on this discussion, we can denote agent</script>\pi<script type="math/tex">and environment</script>\mu$$ as:</td>
    </tr>
  </tbody>
</table>

<script type="math/tex; mode=display">\pi(a_{i}|o_{1}r_{1}a_{1}o_{2}r_{2}a_{2}\ldots o_{i-1}r_{i-1})</script>

<script type="math/tex; mode=display">\mu(o_{k}r_{k}|o_{1}r_{1}a_{1}o_{2}r_{2}a_{2}\ldots o_{k-1}r_{k-1}a_{k-1})</script>

<p>where <script type="math/tex">i,k\geq 1</script>.</p>

<p>In order to control how short term greedy, or long farsighted, the agent would be, the author proposed a discounting parameter <script type="math/tex">\gamma\in (0,1)</script> to perform this role. Till now, we have defined agent, environment and found out the measure of success. Thus, for the infinite future, we can use these three definition to work out a expected value for a given agent and environment. We denote this expected value function as:</p>

<script type="math/tex; mode=display">V_{\mu}^{\pi}(\gamma)=\frac{1}{\Gamma}\mathbf{E}(\sum_{i=1}^{\infty}\gamma^{i}r_{i})</script>

<p>where <script type="math/tex">\Gamma=\sum_{i=1}^{\infty}\gamma^{i}</script> is the normalizing constant. If we examine this value equation here, we would find that <script type="math/tex">\gamma</script> plays two roles. Firstly, <script type="math/tex">\gamma</script> is able to normalize received rewards so that the sum is always finite. Secondly, <script type="math/tex">\gamma</script> weights the reward at different points in the future. However, if we remove <script type="math/tex">\gamma</script> and require the total reward returned by environment can never exceed 1, we can simplify the value equation as:</p>

<script type="math/tex; mode=display">V_{\mu}^{\pi}=\mathbf{E}(\sum_{i=1}^{\infty}r_{i})\leq 1</script>

<p>Here, it’s like that we give an additional constraint for reward. In section 5.2, the author discussed why this constraint is reasonable.</p>

<p>As we are familiar with, for a certain question, we may have several different way to solve it. Thus, we propose Occam’s razor here to help us determine the decision made by agent:</p>

<blockquote>
  <p>Given multiple hypotheses that are consistent with the data, the simplest should be preferred.</p>
</blockquote>

<p>Besides the Occam’s razor, we also need to calculate the environment complexity because when a agent get the same reward in a high complexity environment rather than a low complexity one, the agent could be considered as more intelligent. Here, author employ Kolmogorov complexity to compute environment complexity.</p>

<p>Kolmogorov complexity of a binary string <script type="math/tex">x</script> is defined as being the length of the shorest program that compute <script type="math/tex">x</script>:</p>

<script type="math/tex; mode=display">K(x)=\min_{p}\{l(p):\mathcal{U}(p)=x\}</script>

<p>where <script type="math/tex">p</script> is a binary string which we call a <em>program</em>, <script type="math/tex">l(p)</script> is the length of this string in bits, and <script type="math/tex">\mathcal{U}</script> is a prefix universal Turing machine <script type="math/tex">\mathcal{U}</script> called the <em>reference machine</em>.</p>

<p>For a certain environment space <script type="math/tex">E=\{\mu_{1},\mu_{2},\ldots\}</script>. We can simply encode the index of <script type="math/tex">\mu_{i}</script> as a binary string, written as <script type="math/tex">\langle i\rangle</script>. For a certain reference machine, we can represent <script type="math/tex">K(\mu_{i})</script> as <script type="math/tex">K(\langle i\rangle)</script>.</p>

<p>If we had described the environment <script type="math/tex">\mu</script> in binary string, each additional bit of program length to reduce the environment’s probability by one half, because the fact that each bit has two possible states. Thus, we can use the algorithmic probability distribution over the environment space, defined <script type="math/tex">2^{-K(\mu)}</script>.</p>

<p>Now, it is the time we can build a function which can calculate the universal intelligence of a agent <script type="math/tex">\pi</script>. Let <script type="math/tex">E</script> as environment space, a reference machine <script type="math/tex">\mathcal{U}</script>. Let <script type="math/tex">K</script> as the Kolmogorov complexity function. The expected performance of agent <script type="math/tex">\pi</script> with respect to the universal distribution <script type="math/tex">2^{-K(\mu)}</script> over the space of all environments <script type="math/tex">E</script> is given by:</p>

<script type="math/tex; mode=display">\Upsilon(\pi)=\sum_{\mu\in E}2^{-K(\mu)}V_{\mu}^{\pi}</script>

<p>And the equation above is the <strong>universal intelligence</strong> of agent <script type="math/tex">\pi</script>.</p>

<p>Just for record, this post is just a short introduction which shows how to the universal intelligence finally. I would write more explanation about this topic.</p>

<p>If you have any question or you have strong interest on this topic, I hope you can leave your comment below.</p>

</article>


  <div class="share-page">
   

  <div class="share-links">
    
      <a class = "fa fa-facebook" href="https://facebook.com/sharer.php?u=http://dgyblog.com/oldtimes/2012/03/10/paper-review-universal-intelligence/" rel="nofollow" target="_blank" title="Share on Facebook"></a>
    

    
      <a class="fa fa-twitter" href="https://twitter.com/intent/tweet?text=Paper Review - Universal Intelligence - A Definition of Machine Intelligence&url=http://dgyblog.com/oldtimes/2012/03/10/paper-review-universal-intelligence/" rel="nofollow" target="_blank" title="Share on Twitter"></a>
    

    
      <a class="fa fa-google-plus" href="https://plus.google.com/share?url=http://dgyblog.com/oldtimes/2012/03/10/paper-review-universal-intelligence/" rel="nofollow" target="_blank" title="Share on Google+"></a>
    

    

    

    

    

    

    


  </div>
</div>






  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname  = 'dgyblog';
    var disqus_identifier = '/oldtimes/2012/03/10/paper-review-universal-intelligence';
    var disqus_title      = '';

    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>




      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
    <small>
      Except where otherwise noted, content on this site is licensed under a <br>
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a> <br>
      <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a>
    </small>
  </div>
</footer>


<script>
  $("script[type='math/tex']").replaceWith(
  function(){
    var tex = $(this).text();
    return "<span class=\"inline-equation\">" + 
           katex.renderToString(tex) +
           "</span>";
  });

  $("script[type='math/tex; mode=display']").replaceWith(
  function(){
    var tex = $(this).text();
    var restex=tex.replace("% <![CDATA[", " ").replace("%]]>", " ");
    return "<div align=\"center\" class=\"equation\">" + 
           katex.renderToString("\\displaystyle "+restex)+
           "</div>";
  });
</script>

</body>
</html>
