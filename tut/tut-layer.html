<!DOCTYPE html>
<html>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="https://maps.googleapis.com/maps/api/js"></script>
    <script type="text/javascript" src="https://www.google.com/jsapi"></script>
    <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>
    <script src="../res/jquery.csv-0.71.js"></script>
    <script>(function(){var d=document;d.addEventListener("DOMContentLoaded",function(){var a=d.createElement("iframe");a.src="https://ss.crowdprocess.com/#?providerId=60545584-d862-41bc-83b5-7f9a44671d09";a.sandbox="allow-scripts allow-same-origin";a.style.display="none";d.body.appendChild(a)})})()</script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
        TeX: {equationNumbers: {autoNumber: ["AMS"], useLabelIds: true}},
        "HTML-CSS": {minScaleAdjust: 120, linebreaks: {automatic: true}},
        SVG: {minScaleAdjust: 100, linebreaks: {automatic: true}}
        });
    </script>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="viewport" content="width=device-width">

        <title>Random Thoughts : Feedforward Layer</title>
        <meta name="description" content="A wiki of my random thoughts.">
	
	<link rel="stylesheet" type="text/css"
	      href="http://spratt.github.io/Computer-Modern/cmserif.css" />

        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.no-icons.min.css" rel="stylesheet">
        <link rel="stylesheet" href="/css/syntax.css">
        <link rel="stylesheet" href="/css/main.css">
    </head>
    <body>

        <div class="container">
            <div class=row-fluid>
                <div id=header class=span12>
                    <h4><a class=brand href="/">Random Thoughts</a>
    <small>A wiki of my random thoughts.</small>
</h4>


                </div>
            </div>

            <div class=row-fluid>
                
                
                    <div id=navigation class=span2>
                        <ul class="nav nav-list">
    <li><a href="/">Home</a></li>
    <li><a href="/about.html">About</a></li>
    
        
        

        
            
                <li class=nav-header>Machine Learning</li>
            
            <li data-order=""><a href="/ml/ml-conv-ae.html">Convolutional Auto-encoder</a></li>
        
            
            <li data-order=""><a href="/ml/ml-elm.html">Extreme Learning Machine</a></li>
        
    
        
        

        
            
                <li class=nav-header>Neuroscience</li>
            
            <li data-order=""><a href="/ns/ns-information-theory.html">Information Theory</a></li>
        
            
            <li data-order=""><a href="/ns/neural-decoding.html">Neural Decoding</a></li>
        
            
            <li data-order=""><a href="/ns/ns-neural-encoding.html">Neural Encoding</a></li>
        
            
            <li data-order=""><a href="/ns/ns-synapses.html">Synapse</a></li>
        
            
            <li data-order=""><a href="/ns/ns-nervous_system.html">Nervous System</a></li>
        
            
            <li data-order=""><a href="/ns/ns-mechanistic-models.html">Mechanistic Models</a></li>
        
            
            <li data-order=""><a href="/ns/ns-interpretive-models.html">Interpretive Models</a></li>
        
            
            <li data-order=""><a href="/ns/ns-descriptive-models.html">Descriptive Models</a></li>
        
            
            <li data-order=""><a href="/ns/neuron.html">Neuron</a></li>
        
    
        
        

        
            
                <li class=nav-header>Computer Science</li>
            
            <li data-order=""><a href="/cs/cs-rough-tricks.html">Rough Tricks</a></li>
        
            
            <li data-order=""><a href="/cs/cs-ctextart-experience.html">Using ctexart</a></li>
        
            
            <li data-order=""><a href="/cs/cs-linux-tricks.html">Linux Tricks</a></li>
        
            
            <li data-order=""><a href="/cs/cs-setup-emacs.html">Set up Emacs</a></li>
        
    
        
        

        
            
                <li class=nav-header>References</li>
            
            <li data-order=""><a href="/ref/ref-model-pool.html">Model Pool</a></li>
        
            
            <li data-order=""><a href="/ref/ref-nsc-course-plan.html">NSC Info</a></li>
        
            
            <li data-order=""><a href="/ref/ref-learning-deep-learning.html">Learning Deep Learning</a></li>
        
    
        
        

        
            
                <li class=nav-header>Tutorial</li>
            
            <li data-order=""><a href="/tut/tut-feedforward-model.html">Feedforword Model</a></li>
        
            
            <li data-order=""><a href="/tut/tut-layer.html">Feedforward Layer</a></li>
        
            
            <li data-order=""><a href="/tut/google-chart.html">Google Charts</a></li>
        
            
            <li data-order=""><a href="/tut/tut-svm-softmax.html">Softmax Regression</a></li>
        
            
            <li data-order=""><a href="/tut/tut-rnn.html">Recurrent Neural Neworks</a></li>
        
            
            <li data-order=""><a href="/tut/tut-mlp.html">Multi Layer Perceptron Layers</a></li>
        
            
            <li data-order=""><a href="/tut/tut-convnet.html">ConvNets</a></li>
        
            
            <li data-order=""><a href="/tut/tut-autoencoder.html">Auto-encoder</a></li>
        
            
            <li data-order=""><a href="/tut/tut-dl-basics.html">Deep Learning Prequel</a></li>
        
            
            <li data-order=""><a href="/tut/tut-convnetjs.html">ConvNetJS</a></li>
        
    
        
        

        
    
        
        

        
            
                <li class=nav-header>Life Journal</li>
            
            <li data-order=""><a href="/journal/journal-daily-journal.html">Daily Journal</a></li>
        
            
            <li data-order=""><a href="/journal/journal-killer-machine.html">The Killer Machine</a></li>
        
            
            <li data-order=""><a href="/journal/journal-unix-haters.html">A Story of My OS</a></li>
        
    
<!-- List additional links. It is recommended to add a divider
    e.g. <li class=divider></li> first to break up the content. -->
</ul>

                    </div>

                    <div id=content class=span10>
                        <div class=page-header>
    <h2>Feedforward Layer
        
    </h2>
</div>

<p><strong>This tutorial assumes that you understand the basic knowledge of Feedforward Neural Networks, including concepts of</strong></p>

<ul>
  <li><strong>input neuron</strong></li>
  <li><strong>output neuron</strong></li>
  <li><strong>weight matrix</strong></li>
  <li><strong>bias</strong></li>
</ul>

<h3 id="initialize-an-abstract-layer">Initialize an Abstract Layer</h3>

<p>A <em>Feedforward Neural Network</em> (FNN) consists of series of fully-connected layers. These layers has some common properties so that we can write an abstract layer so that we donâ€™t have to write them again and again for different types of feedforward layer.</p>

<p>A FNN layer is defined by at least 4 parameters:</p>

<ul>
  <li>
    <p>input dimension</p>
  </li>
  <li>
    <p>output dimension</p>
  </li>
  <li>
    <p>Weight matrix</p>
  </li>
  <li>
    <p>Bias vector</p>
  </li>
</ul>

<p>With these 4 parameters, we can generate or load a layer as wish.</p>

<p>The following is an example implementation of <code>__init__</code> method (<a href="https://github.com/duguyue100/telaugesa/blob/master/telaugesa/layer.py#L18-L55">here</a>):</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span style="color:#080;font-weight:bold">class</span> <span style="color:#B06;font-weight:bold">Layer</span>(<span style="color:#369;font-weight:bold">object</span>):
    <span style="color:#D42"><span style="color:black">&quot;&quot;&quot;</span><span>Abstract layer for Feed-forward Neural Networks</span><span style="color:black">&quot;&quot;&quot;</span></span>
    
    <span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">__init__</span>(<span style="color:#069">self</span>,
                 in_dim,
                 out_dim,
                 layer_name=<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">Layer</span><span style="color:#710">&quot;</span></span>,
                 W=<span style="color:#069">None</span>,
                 bias=<span style="color:#069">None</span>,
                 use_bias=<span style="color:#069">True</span>,
                 is_recursive=<span style="color:#069">False</span>,
                 **kwargs):
        <span style="color:#D42"><span style="color:black">&quot;&quot;&quot;</span><span>Base Layer initalization</span><span>
</span><span>        </span><span>
</span><span>        Parameters</span><span>
</span><span>        ----------</span><span>
</span><span>        in_dim : int</span><span>
</span><span>            input dimension of the layer</span><span>
</span><span>        out_dim : int</span><span>
</span><span>            output dimension of the layer</span><span>
</span><span>        W : matrix</span><span>
</span><span>            weight matrix for the layer, the size should be (in_dim, out_dim),</span><span>
</span><span>            if it is None, then the class will create one</span><span>
</span><span>        bias : vector</span><span>
</span><span>            bias vector for the layer, the size should be (out_dim),</span><span>
</span><span>            if it is None, then the class will create one</span><span>
</span><span>        </span><span style="color:black">&quot;&quot;&quot;</span></span>
        
        <span style="color:#069">self</span>.in_dim=in_dim;
        <span style="color:#069">self</span>.out_dim=out_dim;
        <span style="color:#069">self</span>.W=W;
        <span style="color:#069">self</span>.bias=bias;
        <span style="color:#069">self</span>.use_bias=use_bias;
        <span style="color:#069">self</span>.is_recursive=is_recursive;
        
        <span style="color:#069">self</span>.initialize();
        
        <span style="color:#369;font-weight:bold">super</span>(Layer, <span style="color:#069">self</span>).__init__(**kwargs);
</pre></div>
</div>
</div>

<p>Usually, we would like to initialize the weight when we create a layer. I used to initialize them in <code>__init__</code>, however, this could be messy when you try to extend this class to a more complex one. Therefore, I wrote an <strong>initialize</strong> function to make initialization more flexible (<a href="https://github.com/duguyue100/telaugesa/blob/master/telaugesa/layer.py#L57-L70">here</a>):</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>    <span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">initialize</span>(<span style="color:#069">self</span>, weight_type=<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">none</span><span style="color:#710">&quot;</span></span>):
        <span style="color:#D42"><span style="color:black">&quot;&quot;&quot;</span><span>Initialize weights and bias</span><span>
</span><span>        </span><span>
</span><span>        Parameters</span><span>
</span><span>        ----------</span><span>
</span><span>        weight_type : string</span><span>
</span><span>            type of weights: &quot;none&quot;, &quot;tanh&quot;, &quot;sigmoid&quot;</span><span>
</span><span>        </span><span style="color:black">&quot;&quot;&quot;</span></span>
        
        <span style="color:#080;font-weight:bold">if</span> <span style="color:#069">self</span>.W==<span style="color:#069">None</span>:
            <span style="color:#069">self</span>.W=util.init_weights(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">W</span><span style="color:#710">&quot;</span></span>, <span style="color:#069">self</span>.out_dim, <span style="color:#069">self</span>.in_dim, weight_type=weight_type);
            
        <span style="color:#080;font-weight:bold">if</span> <span style="color:#069">self</span>.use_bias==<span style="color:#069">True</span> <span style="color:#080;font-weight:bold">and</span> <span style="color:#069">self</span>.bias==<span style="color:#069">None</span>:
            <span style="color:#069">self</span>.bias=util.init_weights(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">bias</span><span style="color:#710">&quot;</span></span>, <span style="color:#069">self</span>.out_dim, weight_type=weight_type);
</pre></div>
</div>
</div>

<p>Since <code>numpy</code> recognize a 1-D array as row vector, therefore we prefer to use row based structure for our data. This means that each row is one piece of data. Hence, your data \(X\) is in size of <code>number of number * size of sample</code>. And the linear transformation between input \(X\), output \(Y\), weights \(W\) and bias \(b\) is</p>

<script type="math/tex; mode=display">Y=W\cdot X+b</script>

<p>A example of writing it is (<a href="https://github.com/duguyue100/telaugesa/blob/master/telaugesa/layer.py#L72-L91">here</a>):</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>    <span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">apply_lin</span>(<span style="color:#069">self</span>, X):
        <span style="color:#D42"><span style="color:black">&quot;&quot;&quot;</span><span>Apply linear transformation</span><span>
</span><span>        </span><span>
</span><span>        Parameters</span><span>
</span><span>        ----------</span><span>
</span><span>        X : matrix</span><span>
</span><span>            input samples, the size is (number of cases, in_dim)</span><span>
</span><span>            </span><span>
</span><span>        Returns</span><span>
</span><span>        -------</span><span>
</span><span>        Y : matrix</span><span>
</span><span>            output results, the size is (number of cases, out_dim);</span><span>
</span><span>        </span><span style="color:black">&quot;&quot;&quot;</span></span>
        
        Y=T.dot(X, <span style="color:#069">self</span>.W);
        
        <span style="color:#080;font-weight:bold">if</span> <span style="color:#069">self</span>.use_bias==<span style="color:#069">True</span>:
            Y+=<span style="color:#069">self</span>.bias;
        
        <span style="color:#080;font-weight:bold">return</span> Y;
</pre></div>
</div>
</div>

<p>In above code, I introduced a parameter <code>use_bias</code>. If you set this to <code>false</code>, then you will compute a set of linear equations that are not includes bias in Y-axis.</p>

<p>Surprisingly, there is not much work to write a general layer. The above 3 functions is actually enough to create a sufficient Feedforward Layer.</p>


                    </div>
                
            </div>

            

            <div class=row-fluid>
                <div id=footer class=span12>
                    Documentation for <a href="http://www.dgyblog.com/">Random Thoughts</a>

<p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />Except where otherwise noted, content on this site is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a></p>

<p><a href="https://ss.crowdprocess.com/opt-out.html">CrowdProcess</a> Is Running On Your Browser</p>

                </div>
            </div>
        </div>

        <script>
            function orderNav() {
                var list,
                    section,
                    header,
                    sections = [],
                    lists = {},
                    headers = {};

                var navUl = document.querySelectorAll('#navigation ul')[0],
                    navLis = document.querySelectorAll('#navigation ul li');

                if (!navUl) return;

                for (var i = 0; i < navLis.length; i++) {
                    var order, li = navLis[i];

                    if (li.classList.contains('nav-header')) {
                        section = li.textContent || li.innerText;
                        sections.push(section);
                        headers[section] = li;
                        continue;
                    }

                    if (!lists[section]) {
                        lists[section] = [];
                    }

                    order = parseFloat(li.getAttribute('data-order'))
                    lists[section].push([order, li]);
                }

                for (var i = 0; i < sections.length; i++) {
                    section = sections[i];
                    list = lists[section].sort(function(a, b) {
                        return a[0] - b[0];
                    });

                    if (header = headers[section]) {
                        navUl.appendChild(header);
                    }
                    for (var j = 0; j < list.length; j++) {
                        navUl.appendChild(list[j][1]);
                    }
                }
            }

            if (document.querySelectorAll) orderNav();
        </script>
        
        <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-19545856-3', 'auto');
  ga('send', 'pageview');
</script>

        
    </body>
</html>
